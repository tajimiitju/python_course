{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://quotes.toscrape.com',\n",
       " 'http://quotes.toscrape.com/page2',\n",
       " 'http://quotes.toscrape.com/page3',\n",
       " 'http://quotes.toscrape.com/page4',\n",
       " 'http://quotes.toscrape.com/page5',\n",
       " 'http://quotes.toscrape.com/page6',\n",
       " 'http://quotes.toscrape.com/page7',\n",
       " 'http://quotes.toscrape.com/page8',\n",
       " 'http://quotes.toscrape.com/page9',\n",
       " 'http://quotes.toscrape.com/page10']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Assignment 2 Advaced by Tajim\n",
    "# topic:\n",
    "# Scrape all data from this url \"http://quotes.toscrape.com/\"\n",
    "# And dump the scrape data in a csv file.\n",
    "# Column Header will be Quote, Author, Tags.\n",
    "# All the tags will be in one cell and they will be separated by hifen \"-\"\n",
    "# Advanced scarp all the 10 pages in 1 code\n",
    "import sys\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen\n",
    "base_url='http://quotes.toscrape.com/page'\n",
    "url_list1 = [10]\n",
    "url_list1[0]='http://quotes.toscrape.com'\n",
    "for i in range(2,11):\n",
    "    url_list1.append(\"{}{}\".format(base_url, str(i)))\n",
    "\n",
    "url_list1\n",
    "# with open('assignment2_Advance_tajim.csv', 'w') as f:\n",
    "#     f.write('Quote, Author, Tags\\n')\n",
    "#     for i in range(0,10):\n",
    "#         urlClnt = urlopen(url_list1[i])\n",
    "#         raw_html = urlClnt.read()\n",
    "#         urlClnt.close()\n",
    "#         page = soup(raw_html, 'html.parser')\n",
    "#         conteiners = page.findAll('div',{'class' : 'quote'})\n",
    "#         cont1 = conteiners[0]\n",
    "#         for cont1 in conteiners:\n",
    "#             Quote = cont1.find('span',{'class':'text'}).text.replace(',','').replace('\\u2032','')\n",
    "#             Author= cont1.find('small',{'class':'author'}).text.replace('\\u2032','')\n",
    "#             Tags = cont1.find('div',{'class':'tags'}).text.replace('\\n','-').replace('-            Tags:-            -','').replace('\\u2032','')\n",
    "#             f.write(Quote+','+Author+','+Tags+'\\n')\n",
    "#             #print(Quote+','+Author+','+Tags+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
